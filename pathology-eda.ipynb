{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18647,"databundleVersionId":1126921,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet openslide-python opencv-python scikit-image pillow matplotlib pandas\n!pip install --quiet timm segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T04:45:15.693250Z","iopub.execute_input":"2025-09-14T04:45:15.693897Z","iopub.status.idle":"2025-09-14T04:46:23.056660Z","shell.execute_reply.started":"2025-09-14T04:45:15.693872Z","shell.execute_reply":"2025-09-14T04:46:23.055986Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from pathlib import Path\nimport os, random, glob, sys, subprocess\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport openslide\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n\nTRAIN_DIR = Path(\"/kaggle/input/prostate-cancer-grade-assessment/train_images\")\nMASK_DIR  = Path(\"/kaggle/input/prostate-cancer-grade-assessment/train_label_masks\")\nOUT_DIR   = Path(\"/kaggle/working/panda_simple\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\nN_TRAIN_SLIDES = 10\nN_VAL_SLIDES   = 3\nN_TEST_SLIDES  = 3\n\nLEVEL        = 1\nPATCH_SIZE   = 512\nSTRIDE       = 512\nPOS_MAX      = 500\nNEG_MAX      = 300\nTISSUE_MIN_PCT = 0.05\n\nBATCH_SIZE   = 8\nEPOCHS       = 40\nLR           = 2e-4\nNUM_WORKERS  = 0\nIMNET_MEAN   = (0.485, 0.456, 0.406)\nIMNET_STD    = (0.229, 0.224, 0.225)\nMODEL_PATH   = OUT_DIR / \"unet_best.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T06:30:55.233016Z","iopub.execute_input":"2025-09-14T06:30:55.233454Z","iopub.status.idle":"2025-09-14T06:30:55.240547Z","shell.execute_reply.started":"2025-09-14T06:30:55.233432Z","shell.execute_reply":"2025-09-14T06:30:55.240040Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef tissue_mask_rgb(img_rgb):\n    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n    S = hsv[...,1] / 255.0; V = hsv[...,2] / 255.0\n    return (S > 0.07) & (V > 0.20) & (V < 0.95)\n\ndef tumor_bool_from_gray(mask_gray):\n    u = set(np.unique(mask_gray).tolist())\n    if any(x in u for x in (3,4,5)):\n        return np.isin(mask_gray, [3,4,5])\n    elif 2 in u:\n        return (mask_gray == 2)\n    else:\n        return np.zeros_like(mask_gray, dtype=bool)\n\ndef list_slide_ids():\n    ids = []\n    for p in TRAIN_DIR.glob(\"*.tiff\"):\n        sid = p.stem\n        if (MASK_DIR / f\"{sid}_mask.tiff\").exists():\n            ids.append(sid)\n    return sorted(ids)\n\ndef choose_mask_level(mask, target_down):\n    downs = [float(d) for d in mask.level_downsamples]\n    return int(np.argmin([abs(d - target_down) for d in downs]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_one_slide(sid, level=LEVEL, patch=PATCH_SIZE, stride=STRIDE,\n                      pos_max=POS_MAX, neg_max=NEG_MAX, tissue_min=TISSUE_MIN_PCT):\n    slide_path = str(TRAIN_DIR / f\"{sid}.tiff\")\n    mask_path  = str(MASK_DIR  / f\"{sid}_mask.tiff\")\n    ss = openslide.OpenSlide(slide_path)\n    ms = openslide.OpenSlide(mask_path)\n    level_slide = min(level, ss.level_count-1)\n    down_slide  = float(ss.level_downsamples[level_slide])\n    wL, hL      = ss.level_dimensions[level_slide]\n    level_mask  = choose_mask_level(ms, down_slide)\n    W0s, H0s = ss.level_dimensions[0]\n    W0m, H0m = ms.level_dimensions[0]\n    rx, ry   = (W0m / W0s, H0m / H0s)\n    sdir = OUT_DIR / \"tiles\" / sid\n    (sdir / \"img\").mkdir(parents=True, exist_ok=True)\n    (sdir / \"msk\").mkdir(parents=True, exist_ok=True)\n    rows, pos, neg = [], 0, 0\n    for y in range(0, max(hL - patch, 0) + 1, stride):\n        if pos >= pos_max and neg >= neg_max: break\n        for x in range(0, max(wL - patch, 0) + 1, stride):\n            if pos >= pos_max and neg >= neg_max: break\n            x0 = int(x * down_slide); y0 = int(y * down_slide)\n            img = np.array(ss.read_region((x0, y0), level_slide, (patch, patch)).convert(\"RGB\"))\n            mx0 = int(x0 * rx); my0 = int(y0 * ry)\n            try:\n                m_rgba = ms.read_region((mx0, my0), level_mask, (patch, patch))\n            except Exception:\n                continue\n            m_arr = np.array(m_rgba)\n            if m_arr.size == 0: \n                continue\n            mgray = m_arr[..., 0].astype(np.uint8)\n            tumor = tumor_bool_from_gray(mgray)\n            if tumor.any():\n\n                ip = sdir / \"img\" / f\"{sid}_x{x}_y{y}.png\"\n                mp = sdir / \"msk\" / f\"{sid}_x{x}_y{y}.png\"\n                cv2.imwrite(str(ip), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n                cv2.imwrite(str(mp), (tumor.astype(np.uint8) * 255))\n                rows.append([str(ip), str(mp), 1, sid]); pos += 1\n            else:\n\n                if tissue_mask_rgb(cv2.resize(img, (256, 256))).mean() < tissue_min:\n                    continue\n                ip = sdir / \"img\" / f\"{sid}_x{x}_y{y}.png\"\n                mp = sdir / \"msk\" / f\"{sid}_x{x}_y{y}.png\"\n                cv2.imwrite(str(ip), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n                cv2.imwrite(str(mp), (tumor.astype(np.uint8) * 255))\n                rows.append([str(ip), str(mp), 0, sid]); neg += 1\n    ss.close(); ms.close()\n    return rows, pos, neg","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_split(ids, name):\n    all_rows, total_pos, total_neg = [], 0, 0\n    for sid in ids:\n        rows, pos, neg = process_one_slide(sid)\n        all_rows.extend(rows); total_pos += pos; total_neg += neg\n        print(f\"[{name}] {sid}: pos={pos}, neg={neg}, tiles={pos+neg}\")\n    df = pd.DataFrame(all_rows, columns=[\"img\",\"mask\",\"has_tumor\",\"slide_id\"])\n    df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n    out_csv = OUT_DIR / f\"{name}.csv\"\n    df.to_csv(out_csv, index=False)\n    print(f\"[{name}] saved {len(df)} tiles → {out_csv} | pos={total_pos} neg={total_neg}\")\n    return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_ids = list_slide_ids()\nrandom.shuffle(all_ids)\nneed = min(len(all_ids), N_TRAIN_SLIDES + N_VAL_SLIDES + N_TEST_SLIDES)\npicked = all_ids[:need]\nntr = min(N_TRAIN_SLIDES, len(picked))\nnva = min(N_VAL_SLIDES, max(0, len(picked)-ntr))\ntrain_ids = picked[:ntr]\nval_ids   = picked[ntr:ntr+nva]\ntest_ids  = picked[ntr+nva:]\nprint(f\"Slides → train={len(train_ids)} val={len(val_ids)} test={len(test_ids)}\")\n\ntrain_df = build_split(train_ids, \"train\")\nval_df   = build_split(val_ids,   \"val\")\ntest_df  = build_split(test_ids,  \"test\")\nif not (OUT_DIR / \"test.csv\").exists():\n    pd.read_csv(OUT_DIR / \"val.csv\").to_csv(OUT_DIR / \"test.csv\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SegDataset(Dataset):\n    def __init__(self, manifest_csv, augment=False):\n        self.df = pd.read_csv(manifest_csv)\n        self.augment = augment\n        self.mean = np.array(IMNET_MEAN, dtype=np.float32)\n        self.std  = np.array(IMNET_STD,  dtype=np.float32)\n        self.df = self.df.dropna(subset=[\"img\",\"mask\"]).reset_index(drop=True)\n    def __len__(self): return len(self.df)\n    def __getitem__(self, i):\n        row = self.df.iloc[i]\n        img = cv2.cvtColor(cv2.imread(str(row[\"img\"])), cv2.COLOR_BGR2RGB)\n        msk = cv2.imread(str(row[\"mask\"]), cv2.IMREAD_GRAYSCALE)\n        if img is None or msk is None:\n            raise FileNotFoundError(\"bad path\")\n        if self.augment:\n            if random.random() < 0.5:\n                img = np.ascontiguousarray(np.fliplr(img)); msk = np.ascontiguousarray(np.fliplr(msk))\n            if random.random() < 0.5:\n                img = np.ascontiguousarray(np.flipud(img)); msk = np.ascontiguousarray(np.flipud(msk))\n        img = img.astype(np.float32)/255.0\n        img = (img - self.mean)/self.std\n        img = np.transpose(img,(2,0,1))\n        msk = (msk.astype(np.float32)/255.0)[None]\n        return torch.from_numpy(img), torch.from_numpy(msk)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.seq = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(inplace=True)\n        )\n    def forward(self, x): return self.seq(x)\n\nclass UNet(nn.Module):\n    def __init__(self, n_classes=1):\n        super().__init__()\n        self.inc   = DoubleConv(3, 32)\n        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(32, 64))\n        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 256))\n        self.up1   = nn.ConvTranspose2d(256, 256, 2, stride=2)\n        self.dec1  = DoubleConv(256+256, 256)\n        self.up2   = nn.ConvTranspose2d(256, 128, 2, stride=2)\n        self.dec2  = DoubleConv(128+128, 128)\n        self.up3   = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec3  = DoubleConv(64+64, 64)\n        self.up4   = nn.ConvTranspose2d(64, 32, 2, stride=2)\n        self.dec4  = DoubleConv(32+32, 32)\n        self.outc  = nn.Conv2d(32, n_classes, 1)\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x  = self.up1(x5); x = torch.cat([x, x4], dim=1); x = self.dec1(x)\n        x  = self.up2(x);  x = torch.cat([x, x3], dim=1); x = self.dec2(x)\n        x  = self.up3(x);  x = torch.cat([x, x2], dim=1); x = self.dec3(x)\n        x  = self.up4(x);  x = torch.cat([x, x1], dim=1); x = self.dec4(x)\n        return self.outc(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dice_loss(logits, targets, eps=1e-6):\n    probs = torch.sigmoid(logits)\n    num = 2.0 * (probs * targets).sum(dim=(2,3))\n    den = (probs.pow(2) + targets.pow(2)).sum(dim=(2,3)) + eps\n    return (1.0 - num / den).mean()\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(SegDataset(OUT_DIR/\"train.csv\", augment=True),\n                          batch_size=BATCH_SIZE, shuffle=True,\n                          num_workers=NUM_WORKERS, pin_memory=True)\nval_loader   = DataLoader(SegDataset(OUT_DIR/\"val.csv\", augment=False),\n                          batch_size=BATCH_SIZE, shuffle=False,\n                          num_workers=NUM_WORKERS, pin_memory=True)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel  = UNet().to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\nbce = nn.BCEWithLogitsLoss()\nbest_val = 1e9","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(1, EPOCHS+1):\n    model.train(); tr_loss = 0.0\n    for imgs, msks in train_loader:\n        imgs, msks = imgs.to(device), msks.to(device)\n        logits = model(imgs)\n        loss = 0.5 * bce(logits, msks) + 0.5 * dice_loss(logits, msks)\n        optimizer.zero_grad(); loss.backward(); optimizer.step()\n        tr_loss += loss.item() * imgs.size(0)\n    tr_loss /= len(train_loader.dataset)\n    model.eval(); va_loss = 0.0\n    # with torch.no_grad():\n    #     for imgs, msks in val_loader:\n    #         imgs, msks = imgs.to(device), msks.to(device)\n    #         logits = model(imgs)\n    #         loss = 0.5 * bce(logits, msks) + 0.5 * dice_loss(logits, msks)\n    #         va_loss += loss.item() * imgs.size(0)\n    # va_loss /= len(val_loader.dataset)\n    print(f\"Epoch {epoch:02d}  train_loss={tr_loss:.4f} \")\n    # if va_loss < best_val:\n    #     best_val = va_loss\n    torch.save(model.state_dict(), MODEL_PATH)\n    # print(\"saved best model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_rgb_uint8(img_rgb):\n    x = img_rgb.astype(np.float32) / 255.0\n    x = (x - np.array(IMNET_MEAN, np.float32)) / np.array(IMNET_STD, np.float32)\n    x = np.transpose(x, (2,0,1))\n    return torch.from_numpy(x)[None]\n\ndef to_red(mask01):\n    mk = (mask01.astype(np.uint8) * 255)\n    return np.dstack([mk, np.zeros_like(mk), np.zeros_like(mk)])\n\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=device))\nmodel.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_csv(OUT_DIR/\"test.csv\")\nif \"slide_id\" in df_test.columns and len(df_test[\"slide_id\"])>0:\n    slide_id = df_test[\"slide_id\"].iloc[0]\n    df_slide = df_test[df_test[\"slide_id\"] == slide_id].reset_index(drop=True)\nelse:\n    df_slide = df_test.reset_index(drop=True)\n\nK = 12\nsel_pos = df_slide[df_slide[\"has_tumor\"] == 1]\nif len(sel_pos) >= K:\n    sel = sel_pos.head(K).reset_index(drop=True)\nelse:\n    need = min(K - len(sel_pos), len(df_slide))\n    sel = pd.concat([sel_pos, df_slide.sample(need, random_state=SEED)], axis=0).head(K).reset_index(drop=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n\n\nrows = len(sel)\nplt.figure(figsize=(15, 3.2*rows))\nwith torch.no_grad():\n    for i, row in sel.iterrows():\n        img_path = str(row[\"img\"]); msk_path = str(row[\"mask\"])\n        im = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n        gt = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)\n        if im is None or gt is None:\n            continue\n        prob = torch.sigmoid(model(preprocess_rgb_uint8(im).to(device)))[0,0].cpu().numpy()\n        pred01 = (prob >= 0.5).astype(np.uint8)\n        pred_red = to_red(pred01)\n        gt_red   = to_red((gt > 127).astype(np.uint8))\n        overlay  = cv2.addWeighted(im, 0.70, pred_red, 0.60, 0)\n        ax1 = plt.subplot(rows, 5, 5*i+1); ax1.imshow(im);       ax1.set_title(f\"Patch #{i+1}\"); ax1.axis('off')\n        ax2 = plt.subplot(rows, 5, 5*i+2); ax2.imshow(pred_red); ax2.set_title(\"Predicted\");     ax2.axis('off')\n        ax3 = plt.subplot(rows, 5, 5*i+3); ax3.imshow(overlay);  ax3.set_title(\"Overlay\");       ax3.axis('off')\n        ax4 = plt.subplot(rows, 5, 5*i+4); ax4.imshow(gt_red);   ax4.set_title(\"Ground truth\");  ax4.axis('off')\n        ax5 = plt.subplot(rows, 5, 5*i+5); ax5.imshow(prob, cmap='turbo', vmin=0, vmax=1); ax5.set_title(\"Heatmap\"); ax5.axis('off')\nplt.tight_layout(); plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T09:28:01.933382Z","iopub.execute_input":"2025-09-14T09:28:01.933918Z"}},"outputs":[{"name":"stdout","text":"Slides → train=10 val=3 test=3\n[train] e3a86173361dbf0574a3781d540b5259: pos=21, neg=1, tiles=22\n[train] ba99968b0499b6e2dca442a101a2259c: pos=18, neg=0, tiles=18\n[train] 92d2a85fdb81d51f59c5781eb2c5d0a8: pos=5, neg=0, tiles=5\n[train] fa1a79a5248bf5f5742fb14dabc070c6: pos=7, neg=0, tiles=7\n[train] 6ad78c89d6b8feadad6d3ad85c743e32: pos=6, neg=0, tiles=6\n[train] f2f9aa01d545ac770dce5e61e6d756d4: pos=5, neg=0, tiles=5\n[train] 933f22ce388303435d472aa4f9a56d66: pos=13, neg=2, tiles=15\n[train] fa6a2270986c61fcb0a34e9dd91a910c: pos=6, neg=10, tiles=16\n[train] 903c88d5dc12315b4f6e9d6ad6b82537: pos=13, neg=0, tiles=13\n[train] 919408ee796bb1d71ca9fc5ee0019400: pos=15, neg=11, tiles=26\n[train] saved 133 tiles → /kaggle/working/panda_simple/train.csv | pos=109 neg=24\n[val] c449f43f419bef77e8f8569de2858199: pos=11, neg=12, tiles=23\n[val] bcc84573e785de42d7af076ae2b30479: pos=10, neg=0, tiles=10\n[val] 80b57cbfbaa4a0565a5e4839c24223b6: pos=8, neg=0, tiles=8\n[val] saved 41 tiles → /kaggle/working/panda_simple/val.csv | pos=29 neg=12\n[test] 52f458343920a7409c42f4ec0a9cc8e0: pos=32, neg=0, tiles=32\n[test] a1867f63370ccdb636e2ec006b5f0a6a: pos=0, neg=19, tiles=19\n[test] 209e212fd587a016db5b429425778aa5: pos=0, neg=19, tiles=19\n[test] saved 70 tiles → /kaggle/working/panda_simple/test.csv | pos=32 neg=38\nEpoch 01  train_loss=0.6523  val_loss=0.6900\nsaved best model\nEpoch 02  train_loss=0.5859  val_loss=0.5935\nsaved best model\nEpoch 03  train_loss=0.5615  val_loss=0.5664\nsaved best model\nEpoch 04  train_loss=0.5426  val_loss=0.5520\nsaved best model\nEpoch 05  train_loss=0.5383  val_loss=0.5410\nsaved best model\nEpoch 06  train_loss=0.5241  val_loss=0.5350\nsaved best model\nEpoch 07  train_loss=0.5185  val_loss=0.5318\nsaved best model\nEpoch 08  train_loss=0.5073  val_loss=0.5294\nsaved best model\nEpoch 09  train_loss=0.4907  val_loss=0.5280\nsaved best model\nEpoch 10  train_loss=0.4806  val_loss=0.5109\nsaved best model\nEpoch 11  train_loss=0.4711  val_loss=0.5062\nsaved best model\nEpoch 12  train_loss=0.4650  val_loss=0.5122\nEpoch 13  train_loss=0.4527  val_loss=0.4755\nsaved best model\nEpoch 14  train_loss=0.4566  val_loss=0.4951\nEpoch 15  train_loss=0.4435  val_loss=0.4856\nEpoch 16  train_loss=0.4389  val_loss=0.4697\nsaved best model\nEpoch 17  train_loss=0.4256  val_loss=0.4801\nEpoch 18  train_loss=0.4227  val_loss=0.4641\nsaved best model\nEpoch 19  train_loss=0.4150  val_loss=0.4431\nsaved best model\nEpoch 20  train_loss=0.4046  val_loss=0.4566\nEpoch 21  train_loss=0.3950  val_loss=0.4546\nEpoch 22  train_loss=0.3883  val_loss=0.4414\nsaved best model\nEpoch 23  train_loss=0.3926  val_loss=0.4311\nsaved best model\nEpoch 24  train_loss=0.3768  val_loss=0.4414\nEpoch 25  train_loss=0.3768  val_loss=0.4496\nEpoch 26  train_loss=0.3708  val_loss=0.4033\nsaved best model\nEpoch 27  train_loss=0.3668  val_loss=0.4385\nEpoch 28  train_loss=0.3637  val_loss=0.4167\nEpoch 29  train_loss=0.3656  val_loss=0.3956\nsaved best model\nEpoch 30  train_loss=0.3568  val_loss=0.4373\nEpoch 31  train_loss=0.3515  val_loss=0.4325\nEpoch 32  train_loss=0.3431  val_loss=0.3842\nsaved best model\nEpoch 33  train_loss=0.3387  val_loss=0.4028\nEpoch 34  train_loss=0.3378  val_loss=0.3905\nEpoch 35  train_loss=0.3388  val_loss=0.3986\nEpoch 36  train_loss=0.3295  val_loss=0.3895\nEpoch 37  train_loss=0.3239  val_loss=0.3898\nEpoch 38  train_loss=0.3258  val_loss=0.3864\nEpoch 39  train_loss=0.3199  val_loss=0.3822\nsaved best model\nEpoch 40  train_loss=0.3201  val_loss=0.4202\nEpoch 41  train_loss=0.3196  val_loss=0.3740\nsaved best model\nEpoch 42  train_loss=0.3165  val_loss=0.3775\nEpoch 43  train_loss=0.3200  val_loss=0.4137\nEpoch 44  train_loss=0.3068  val_loss=0.3618\nsaved best model\nEpoch 45  train_loss=0.3052  val_loss=0.4013\nEpoch 46  train_loss=0.2966  val_loss=0.3629\nEpoch 47  train_loss=0.3017  val_loss=0.3541\nsaved best model\nEpoch 48  train_loss=0.2990  val_loss=0.4126\nEpoch 49  train_loss=0.3027  val_loss=0.3623\nEpoch 50  train_loss=0.2913  val_loss=0.3515\nsaved best model\nEpoch 51  train_loss=0.2961  val_loss=0.3570\nEpoch 52  train_loss=0.2858  val_loss=0.3438\nsaved best model\nEpoch 53  train_loss=0.3056  val_loss=0.3633\nEpoch 54  train_loss=0.2883  val_loss=0.3647\nEpoch 55  train_loss=0.2838  val_loss=0.3747\nEpoch 56  train_loss=0.2875  val_loss=0.3607\nEpoch 57  train_loss=0.2822  val_loss=0.3637\nEpoch 58  train_loss=0.2774  val_loss=0.3545\nEpoch 59  train_loss=0.2749  val_loss=0.3559\nEpoch 60  train_loss=0.2709  val_loss=0.3564\nEpoch 61  train_loss=0.2814  val_loss=0.3602\nEpoch 62  train_loss=0.2799  val_loss=0.3412\nsaved best model\nEpoch 63  train_loss=0.2786  val_loss=0.3521\nEpoch 64  train_loss=0.2753  val_loss=0.3539\nEpoch 65  train_loss=0.2707  val_loss=0.3575\nEpoch 66  train_loss=0.2706  val_loss=0.3389\nsaved best model\nEpoch 67  train_loss=0.2664  val_loss=0.3461\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}